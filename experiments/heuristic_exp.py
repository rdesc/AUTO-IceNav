"""Computes the mean number of expanded nodes in graph search"""
import os
import pickle
from copy import deepcopy
from datetime import datetime
from multiprocessing import Queue

import pandas as pd

from ship_ice_planner.launch import launch
from ship_ice_planner.src.utils.utils import DotDict


# loads the experiment configurations generated by `python generate_rand_exp.py`
EXPERIMENT_CONFIG_FILE = 'experiments/experiments_02-05_100.pk'
# contains the parameters of the planner and simulation
PLANNER_CONFIG_FILE = 'configs/sim_config.yaml'
# name for the base directory of all experiment output files
RUN_DIR_NAME = 'heuristic-test'


def main(cfg_file, run_name):
    base_cfg = DotDict.load_from_file(cfg_file)
    base_cfg.planner = 'lattice'
    base_cfg.output_dir = os.path.join('output', run_name)
    base_cfg.plot.show = False
    base_cfg.a_star.h_baseline = False
    base_cfg.threshold_dist = 0

    if base_cfg.output_dir:
        # if dir already exists, make a new one with same name but with added date prefix
        if os.path.isdir(base_cfg.output_dir):
            base_cfg.output_dir += '-' + str(datetime.now().strftime('%m-%d_%H:%M:%S'))

    # generate a separate config for each planner
    cfg1 = deepcopy(base_cfg)
    cfg1.a_star.h_baseline = True

    planners = [
        ('ours', deepcopy(base_cfg)),
        ('baseline', cfg1),
    ]

    for conc in exp_dict:
        print('\nConcentration:', conc)

        for (planner, cfg) in planners:
            print('Planner', planner)
            queue = Queue()
            cfg.output_dir = os.path.join(base_cfg.output_dir, str(conc), planner)
            cfg.max_replan = len(exp_dict[conc])

            for trial in exp_dict[conc]:
                print('Trial', trial)
                exp = deepcopy(exp_dict[conc][trial])
                goal, start, obs_dicts = exp.values()
                obstacles = [ob['vertices'] for ob in obs_dicts]
                queue.put(dict(
                    goal=goal,
                    ship_state=start,
                    obstacles=obstacles
                ))

            results = launch(cfg=cfg, debug=False, logging=True, queue=queue)
            data.extend([{'planner': planner, 'concentration': conc, 'trial': i, **item}
                         for i, item in enumerate(results)])

    df = pd.DataFrame(data)
    df.to_csv(os.path.join(base_cfg.output_dir, 'results.csv'))

    # print some stats
    print_cols = ['expanded_cnt', 'compute_time', 'g_score', 'path_length']
    for h in ['ours', 'baseline']:
        print('\nheuristic', h)
        print(df[df['planner'] == h][print_cols].describe())

    ratio = df[df['planner'] == 'ours']['expanded_cnt'].to_numpy() \
            / df[df['planner'] == 'baseline']['expanded_cnt'].to_numpy()
    print('\nExpanded node improvement')
    print('mean', 1-ratio.mean(), '\nmax', 1-ratio.min(), '\nmin', 1-ratio.max())


if __name__ == '__main__':
    data = []
    ddict = pickle.load(open(EXPERIMENT_CONFIG_FILE, 'rb'))
    exp_dict = ddict['exp']
    main(cfg_file=PLANNER_CONFIG_FILE,
         run_name=RUN_DIR_NAME)
